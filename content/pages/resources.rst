Resources
*********

Data records
============

**Multi-faceted brain imaging and behavioral measurements.**

At this point, data from 20 human participants is publicly
available.  For each participant a number of different scans and auxiliary
recordings have been obtained. In addition, several types of minimally
preprocessed data are also provided. The total size of all data is several
hundred gigabytes. This page provides an overview of the dataset in order
to aid a researcher's selection of sub-components. The full description
of the data releases are available in dedicated publications.

.. raw:: html

  <table class="table table-striped">
  <thead>
    <tr>
      <th>#</th>
      <th>Publication</th>
      <th>Authors</th>
      <th>Get access</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">1</th>
      <td>
        A high-resolution 7-Tesla fMRI dataset from complex natural
        stimulation with an audio movie.
        Scientific Data, 1 (2014)
      </td>
      <td>
        Michael Hanke, Florian J. Baumgartner, Pierre Ibe, Falko Kaule,
        Stefan Pollmann, Oliver Speck, Wolf Zinke, Jörg Stadler
      </td>
      <td>
        <a class="btn btn-success"
           href="http://www.nature.com/articles/sdata20143"
           role="button">Open-access</a>
      </td>
    </tr>
    <tr>
      <th scope="row">2</th>
      <td>
         Portrayed emotions in the movie “Forrest Gump”.
         F1000Research, 4:92 (2015)
      </td>
      <td>
         Annika Labs, Theresa Reich, Helene Schulenburg, Manuel Boennen,
         Mareike Gehrke, Madleen Golz, Benita Hartigs, Nico Hoffmann,
         Sebastian Keil, Malú Perlow, Anne Katrin Peukmann, Lea Noell Rabe,
         Franca-Rosa von Sobbe, Michael Hanke
      </td>
      <td>
        <a class="btn btn-success"
           href="http://f1000research.com/articles/4-92"
           role="button">Open-access</a>
      </td>
    </tr>
    <tr>
      <th scope="row">3</th>
      <td>
         High-resolution 7-Tesla fMRI data on the perception
         of musical genres – an extension to the studyforrest
         dataset.
         F1000Research, 4:174 (2015)
      </td>
      <td>
      Michael Hanke, Richard Dinga, Christian Häusler, J. Swaroop Guntupalli,
      Michael Casey, Falko R. Kaule, and Jörg Stadler
      </td>
      <td>
        <a class="btn btn-success"
           href="http://f1000research.com/articles/4-174"
           role="button">Open-access</a>
      </td>
    </tr>
    <tr>
      <th scope="row">4</th>
      <td>
         A block-design fMRI localizer for visual areas – an extension to the
         studyforrest dataset.
         (in prep.)
      </td>
      <td>
      </td>
      <td>
        <a class="btn btn-success disabled"
           href=""
           role="button">not yet</a>
      </td>
    </tr>
  </tbody>
  </table>

Note that this dataset is continously maintained and additions or bug fixes are
made public as soon as they become available. There is a `revision log
<http://psydata.ovgu.de/forrest_gump/release_history.txt>`_ that lists all
significant updates. Data mirrors may not always provide the latest revision.

.. raw:: html

  <div class="row">
    <div class="col-sm-4">
      <a class="iconlink" href="mod_fmri.html">
      <div class="thumbnail">
        <img src="/pics/fmri_thumb.jpg" class="img-responsive" alt="Sample FMRI slices">
        <div class="caption">
          <h5>Functional MRI</h5>
        </div>
      </div>
      </a>
    </div>
    <div class="col-sm-4">
      <a class="iconlink" href="mod_physio.html">
      <div class="thumbnail">
        <img src="/pics/physio_thumb.png" class="img-responsive" alt="Sample curves">
        <div class="caption">
          <h5>Physiological measurements</h5>
        </div>
      </div>
      </a>
    </div>
    <div class="col-sm-4">
      <a class="iconlink" href="mod_annot.html">
      <div class="thumbnail">
        <img src="/pics/annotations_thumb.png" class="img-responsive" alt="Annotation icon">
        <div class="caption">
          <h5>Annotations &amp; surveys</h5>
        </div>
      </div>
      </a>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-4">
      <a class="iconlink" href="mod_t1w.html">
        <div class="thumbnail">
        <img src="/pics/t1w_thumb.jpg" class="img-responsive" alt="T1w sample image">
        <div class="caption"><h5>T1-weighted MRI</h5></div>
        </div>
      </a>
    </div>
    <div class="col-sm-4">
      <a class="iconlink" href="mod_t2w.html">
      <div class="thumbnail">
        <img src="/pics/t2w_thumb.jpg" class="img-responsive" alt="T2w sample image">
        <div class="caption">
          <h5>T2-weighted MRI</h5>
        </div>
      </div>
      </a>
    </div>
    <div class="col-sm-4">
      <a class="iconlink" href="mod_swi.html">
      <div class="thumbnail">
        <img src="/pics/swi_thumb.jpg" class="img-responsive" alt="SWI sample image">
        <div class="caption">
          <h5>Susceptibility-weighted MRI</h5>
        </div>
      </div>
      </a>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-4">
      <a class="iconlink" href="mod_dti.html">
      <div class="thumbnail">
        <img src="/pics/dti_thumb.jpg" class="img-responsive" alt="DTI sample image">
        <div class="caption">
          <h5>Diffusion tensor MRI</h5>
        </div>
      </div>
      </a>
    </div>
    <div class="col-sm-4">
      <a class="iconlink" href="mod_angio.html">
      <div class="thumbnail">
        <img src="/pics/angio_thumb.jpg" class="img-responsive" alt="Angiography max intensity projection">
        <div class="caption">
          <h5>Angiography</h5>
        </div>
      </div>
      </a>
    </div>
    <div class="col-sm-4">
      <a class="iconlink" href="mod_surf.html">
      <div class="thumbnail">
        <img src="/pics/surf_thumb.jpg" class="img-responsive" alt="Sample brain surface mesh">
        <div class="caption">
          <h5>Surface reconstruction</h5>
        </div>
      </div>
      </a>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-4">
      <!--<a class="iconlink" class="disabled" href="">-->
      <div class="thumbnail">
        <img src="/pics/eyemove_thumb.jpg" class="img-responsive" alt="Eyemovement icon" style="opacity:.5">
        <div class="caption">
          <h5>Eye movements</h5>
        </div>
      </div>
      <!--</a>-->
    </div>
    <div class="col-sm-4">
      <!-- <a class="iconlink" href=""> -->
      <div class="thumbnail">
        <img src="/pics/eeg_thumb.jpg" class="img-responsive" alt="EEG topography icon" style="opacity:.5">
        <div class="caption">
          <h5>EEG</h5>
        </div>
      </div>
      <!--</a>-->
    </div>
    <div class="col-sm-4">
      <!-- <a class="iconlink" href=""> -->
      <div class="thumbnail">
        <img src="/pics/eegfmri_thumb.jpg" class="img-responsive" alt="EEG/FMRI icon" style="opacity:.5">
        <div class="caption">
          <h5>Simultaneous EEG/FMRI</h5>
        </div>
      </div>
      <!--</a>-->
    </div>
  </div>


Data acquisition roadmap
------------------------

.. raw:: html

  <div class="col-sm-4" style="text-align:center">
    <img src="/pics/schema_phase1.png"
         alt="Acquisition setup scheme phase 1" />
    <h4>Phase 1<br />(completed)</h4>
    <ul style="list-style:none;padding-left:0px">
      <li>Focus on <strong>natural language processing</strong></li>
      <li>Two hours of natural stimulation with an <strong>audio</strong> movie</li>
      <li><strong>High-resolution fMRI at 7-Tesla</strong> (partial brain coverage)</li>
      <li>Cardiac and respiratory trace at 200 Hz</li>
    </ul>
  </div><!-- /.col-sm-4 -->
  <div class="col-sm-4" style="text-align:center">
    <img src="/pics/schema_phase2.png"
         alt="Acquisition setup scheme phase 2" />
    <h4>Phase 2<br />(in progress)</h4>
    <ul style="list-style:none;padding-left:0px">
      <li>Focus on <strong>visual attention</strong> and <strong>audio-visual integration</strong></li>
      <li>Two hours of natural stimulation with an <strong>audio-visual</strong> movie</li>
      <li>Full-brain fMRI at 3-Tesla</li>
      <li><strong>Simultaneous eye-tracking</strong></li>
      <li>Cardiac and respiratory trace at 500 Hz</li>
    </ul>
  </div><!-- /.col-sm-4 -->
  <div class="col-sm-4" style="text-align:center">
    <img src="/pics/schema_phase3.png"
         alt="Acquisition setup scheme phase 3" />
    <h4>Phase 3<br />(planned)</h4>
    <ul style="list-style:none;padding-left:0px">
      <li>Focus on <strong>fusion of high spatial and high temporal resolution</strong></li>
      <li>Two hours of natural stimulation with an audio-visual movie</li>
      <li>Full-brain fMRI at 3-Tesla</li>
      <li><strong>Simultaneous 64-channel EEG</strong></li>
      <li>Simultaneous eye-tracking</li>
      <li>Cardiac and respiratory trace at 500 Hz</li>
    </ul>
  </div><!-- /.col-sm-4 -->

Software
========

**Readily usable software tools to facilitate exploration and reproducibility.**

.. raw:: html

  <div class="row">
   <div class="col-sm-7">
    <p><a href="http://neuro.debian.net">NeuroDebian</a> is a comprehensive computational environment
    for neuroscientific data analysis. It is compatible with all major
    platforms and offers a large variety of data processing and visualization
    tools, such as
    <a href="http://afni.nimh.nih.gov">AFNI</a>,
    <a href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/">FSL</a> and
    <a href="http://nipy.org/nipype/">NiPype</a>. Moreover, it contains
    all software needed to reproduce the work performed in this project
    and its associated publications (e.g.
    <a href="http://psychopy.org">PsychoPy</a>).
    NeuroDebian can get you started with data analysis in
    matter of minutes and from there on keep your tools up-to-date.
    It is ideal for open-science projects, as ideas can be developed
    and shared as complete and readily usable computational environments.</p>
    <p>NeuroDebian development is lead by <a href="http://www.onerussian.com/">
        Yaroslav Halchenko</a> and <a href="http://mih.voxindeserto.de">
        Michael Hanke</a>,
    and receives contributions from a broad range of scientific software
    developers.</p>
    <p><a class="btn btn-success" href="http://journal.frontiersin.org/Journal/10.3389/fninf.2012.00022/full" target="_blank" role="button">Learn more &raquo;</a></p>
   </div><!-- /.col-sm-7 -->
   <div class="col-sm-5">
    <p><a href="http://neuro.debian.net" title="Visit NeuroDebian site">
     <img src="/pics/neurodebian_logo.png" class="img-responsive center-block" alt="NeuroDebian logo">
    </a></p>
   </div><!-- /.col-sm-5 -->
  </div><!-- /.row -->
  <div class="row">
   <hr />
   <div class="col-sm-5">
       <p><a href="http://www.pymvpa.org">PyMVPA</a> is an analysis framework that is particularly suited for the kind
    of data used by this project. It offers a uniform interface to a large
    variety of toolboxes for data-driven analysis (such as
    <a href="http://scikit-learn.org">scikit-learn</a> and
    <a href="http://mdp-toolkit.sourceforge.net/">MDP</a>), and also provides implementations of cutting-edge
    algorithms like
    <a href="http://www.pymvpa.org/examples/hyperalignment.html">hyperalignment</a>.
    It comes with a <a href="http://www.pymvpa.org/tutorial.html">thorough tutorial</a>
    and a <a href=http://www.pymvpa.org/examples.html>set of examples</a>
    to guide you.</p>
    <p>PyMVPA is free software distributed under the MIT license and
   available from <a href="http://neuro.debian.net">NeuroDebian</a>.</p>
    <p><a class="btn btn-success" href="http://journal.frontiersin.org/Journal/10.3389/neuro.11.003.2009/full" target="_blank" role="button">Learn more &raquo;</a></p>
   </div><!-- /.col-sm-5 -->
   <div class="col-sm-7">
    <a href="http://www.pymvpa.org" title="Visit pymvpa.org">
     <img src="/pics/pymvpa_logo.jpg" class="img-responsive center-block" alt="PyMVPA logo">
    </a>
   </div><!-- /.col-sm-7 -->
  </div><!-- /.row -->
